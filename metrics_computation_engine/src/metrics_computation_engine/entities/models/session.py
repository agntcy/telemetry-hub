# Copyright AGNTCY Contributors (https://github.com/agntcy)
# SPDX-License-Identifier: Apache-2.0

from typing import Any, Dict, List, Optional
from collections import Counter, defaultdict
from pydantic import BaseModel, Field, PrivateAttr

from .span import SpanEntity


class AgentStats(BaseModel):
    """Statistics for a single agent in a session."""

    unique_tool_names: List[str] = Field(
        default_factory=list, description="List of unique tool names used by this agent"
    )
    total_llm_calls: int = Field(
        default=0, description="Total number of LLM calls by this agent"
    )
    total_tool_calls: int = Field(
        default=0, description="Total number of tool calls by this agent"
    )
    llm_calls_failed: int = Field(default=0, description="Number of failed LLM calls")
    tool_calls_failed: int = Field(default=0, description="Number of failed tool calls")
    total_tools_duration: float = Field(
        default=0.0, description="Total duration of tool calls in milliseconds"
    )
    total_llm_duration: float = Field(
        default=0.0, description="Total duration of LLM calls in milliseconds"
    )
    llm_input_tokens: int = Field(
        default=0, description="Total input tokens used by LLM calls"
    )
    llm_output_tokens: int = Field(
        default=0, description="Total output tokens generated by LLM calls"
    )
    llm_total_tokens: int = Field(
        default=0, description="Total tokens (input + output) used by LLM calls"
    )
    tool_total_tokens: int = Field(
        default=0, description="Total tokens used by tools under this agent"
    )


class ConversationElement(BaseModel):
    """Represents a single turn in a conversation."""

    role: str
    content: str


class ToolCall(BaseModel):
    """Represents a tool call with all necessary information."""

    name: str
    description: str
    input_parameters: Dict[str, Any]
    output: Dict[str, Any]


class SessionEntity(BaseModel):
    """
    Pure data model for session-level entity.
    Contains only the fields that are actually used by metrics.
    """

    # Core session metadata
    session_id: str
    # all the session spans ordered by timestamp (from older to newer)
    spans: List[SpanEntity]

    # Timing information
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    duration: Optional[float] = None  # Duration in milliseconds

    # Private field for optimized entity access (built lazily)
    # Previously: duplication of spans filtered by entity type and one field per type
    # Now: single source of truth (spans) + indices for fast filtering
    _entity_indices: Optional[Dict[str, List[int]]] = PrivateAttr(default=None)

    # Data extracted by transformers (used by metrics)
    conversation_data: Optional[Dict[str, Any]] = None
    workflow_data: Optional[Dict[str, Any]] = None

    # Graph-related attributes extracted from graph entity spans
    graph_determinism: Optional[float] = None
    graph_dynamism: Optional[Any] = None
    graph: Optional[Any] = None

    # Hierarchical execution tree showing parent-child relationships
    execution_tree: Optional[Any] = None
    hierarchy_summary: Optional[Dict[str, Any]] = None

    # Agent interaction data (needed by AgentToAgentInteractions)
    agent_transitions: Optional[List[str]] = None
    agent_transition_counts: Optional[Counter] = None

    conversation_elements: Optional[List[ConversationElement]] = None

    tool_calls: Optional[List[ToolCall]] = None

    input_query: Optional[str] = None
    final_response: Optional[str] = None

    def _build_entity_indices(self) -> None:
        """Build indices for efficient entity type filtering."""
        # Only build indices if they haven't been built yet
        if self._entity_indices is not None:
            return

        self._entity_indices = defaultdict(list)
        for i, span in enumerate(self.spans):
            self._entity_indices[span.entity_type].append(i)

    @property
    def agent_spans(self) -> List[SpanEntity]:
        """Get agent spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("agent", [])]

    @property
    def workflow_spans(self) -> List[SpanEntity]:
        """Get workflow spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("workflow", [])]

    @property
    def tool_spans(self) -> List[SpanEntity]:
        """Get tool spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("tool", [])]

    @property
    def llm_spans(self) -> List[SpanEntity]:
        """Get LLM spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("llm", [])]

    @property
    def graph_spans(self) -> List[SpanEntity]:
        """Get graph spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("graph", [])]

    @property
    def task_spans(self) -> List[SpanEntity]:
        """Get task spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("task", [])]

    @property
    def time_range(self) -> str:
        """Get the time range of the session."""
        if self.start_time and self.end_time:
            return f"{self.start_time} - {self.end_time}"
        return "Unknown"

    @property
    def total_spans(self) -> int:
        """Get the total number of spans in the session."""
        return len(self.spans)

    @property
    def all_spans(self) -> List[SpanEntity]:
        """Get all spans in the session (alias for spans)."""
        return self.spans

    @property
    def app_name(self) -> str:
        """
        Extract the application name from session spans.

        Looks for common attributes that might contain the app name.
        Returns a default value if not found.
        """
        # Check for common app name attributes in spans
        for span in self.spans:
            # First, check raw span data for ServiceName
            if span.raw_span_data and span.raw_span_data.get("ServiceName"):
                service_name = str(span.raw_span_data["ServiceName"])
                if service_name and service_name != "unknown":
                    return service_name

            # Then check ResourceAttributes for service.name
            if span.raw_span_data and span.raw_span_data.get("ResourceAttributes"):
                resource_attrs = span.raw_span_data["ResourceAttributes"]
                if isinstance(resource_attrs, dict) and resource_attrs.get(
                    "service.name"
                ):
                    service_name = str(resource_attrs["service.name"])
                    if service_name and service_name != "unknown":
                        return service_name

            # Check span attributes for app name patterns
            if span.attrs:
                # Common patterns for app names
                for attr_key in [
                    "app.name",
                    "service.name",
                    "application.name",
                    "traceloop.workflow.name",
                ]:
                    if span.attrs.get(attr_key):
                        return str(span.attrs[attr_key])

                # Check for workflow names that might indicate app
                workflow_name = span.attrs.get("ioa_workflow.name")
                if workflow_name:
                    return str(workflow_name)

                # Check for agent names as fallback
                if span.entity_type == "agent" and span.entity_name:
                    return str(span.entity_name)

        # Default fallback
        return "unknown-app"

    # Statistics and utility methods

    @property
    def unique_tool_names(self) -> List[str]:
        """Get the list of unique tool names used in the session."""
        tool_names = set()
        for span in self.tool_spans:
            if span.entity_name:
                tool_names.add(span.entity_name)
        return sorted(list(tool_names))

    @property
    def unique_agent_names(self) -> List[str]:
        """Get the list of unique agent names used in the session."""
        agent_names = set()
        for span in self.agent_spans:
            if span.entity_name:
                agent_names.add(span.entity_name)
        return sorted(list(agent_names))

    @property
    def total_llm_calls(self) -> int:
        """Get the total number of LLM calls in the session."""
        return len(self.llm_spans)

    @property
    def total_tool_calls(self) -> int:
        """Get the total number of tool calls in the session."""
        return len(self.tool_spans)

    @property
    def llm_calls_failed(self) -> int:
        """Get the number of failed LLM calls in the session."""
        return sum(1 for span in self.llm_spans if span.contains_error)

    @property
    def tool_calls_failed(self) -> int:
        """Get the number of failed tool calls in the session."""
        return sum(1 for span in self.tool_spans if span.contains_error)

    @property
    def total_tools_duration(self) -> float:
        """Get the total duration of all tool calls in milliseconds."""
        return sum(
            span.duration for span in self.tool_spans if span.duration is not None
        )

    @property
    def total_llm_duration(self) -> float:
        """Get the total duration of all LLM calls in milliseconds."""
        return sum(
            span.duration for span in self.llm_spans if span.duration is not None
        )

    @property
    def llm_input_tokens(self) -> int:
        """Get the total number of input tokens used by all LLM calls."""
        total = 0
        for span in self.llm_spans:
            if span.attrs and span.attrs.get("input_tokens") is not None:
                try:
                    total += int(span.attrs["input_tokens"])
                except (ValueError, TypeError):
                    pass
        return total

    @property
    def llm_output_tokens(self) -> int:
        """Get the total number of output tokens generated by all LLM calls."""
        total = 0
        for span in self.llm_spans:
            if span.attrs and span.attrs.get("output_tokens") is not None:
                try:
                    total += int(span.attrs["output_tokens"])
                except (ValueError, TypeError):
                    pass
        return total

    @property
    def llm_total_tokens(self) -> int:
        """Get the total number of tokens (input + output) used by all LLM calls."""
        total = 0
        for span in self.llm_spans:
            if span.attrs and span.attrs.get("total_tokens") is not None:
                try:
                    total += int(span.attrs["total_tokens"])
                except (ValueError, TypeError):
                    pass
        return total

    @property
    def tool_total_tokens(self) -> int:
        """
        Get the total LLM tokens used by all tools by analyzing the execution tree.

        This method traverses the execution tree to identify LLM calls that are
        descendants of tool spans and aggregates their token usage.

        Returns:
            Total sum of LLM tokens consumed by all tools
        """
        if not self.execution_tree:
            return 0

        tool_tokens = {}

        # Find all tool nodes in the execution tree
        for trace_roots in self.execution_tree.traces.values():
            for root in trace_roots:
                self._collect_tool_llm_tokens(root, tool_tokens)

        # Sum all token values, handling None and -1 values
        total = 0
        for tokens in tool_tokens.values():
            if tokens is not None and tokens >= 0:
                total += tokens

        return total

    def _collect_tool_llm_tokens(self, node, tool_tokens: Dict[str, int]) -> None:
        """
        Recursively traverse the execution tree to collect LLM tokens used by tools.

        Args:
            node: Current SpanNode being processed
            tool_tokens: Dictionary to accumulate token counts per tool
        """
        # If this is a tool node, collect LLM tokens from all descendants
        if node.span.entity_type == "tool":
            tool_name = node.span.entity_name
            if tool_name not in tool_tokens:
                tool_tokens[tool_name] = 0

            # Collect tokens from all LLM descendants
            llm_tokens = self._get_descendant_llm_tokens(node)
            tool_tokens[tool_name] += llm_tokens

        # Continue traversing children
        for child in node.children:
            self._collect_tool_llm_tokens(child, tool_tokens)

    def _get_descendant_llm_tokens(self, node) -> int:
        """
        Get total LLM tokens from all descendant nodes.

        Args:
            node: SpanNode to start traversal from

        Returns:
            Total tokens from all LLM descendants
        """
        total_tokens = 0

        # If this node is an LLM, add its tokens
        if node.span.entity_type == "llm":
            if node.span.attrs and node.span.attrs.get("total_tokens") is not None:
                try:
                    token_value = int(node.span.attrs["total_tokens"])
                    # Only add positive values, skip None and -1
                    if token_value >= 0:
                        total_tokens += token_value
                except (ValueError, TypeError):
                    # Skip invalid token values
                    pass

        # Recursively check all children
        for child in node.children:
            total_tokens += self._get_descendant_llm_tokens(child)

        return total_tokens

    @property
    def agent_stats(self) -> Dict[str, AgentStats]:
        """
        Get comprehensive statistics for each agent in the session.

        This method analyzes the execution tree to identify spans that belong to each agent
        and calculates the same statistics as the session-level methods.

        Returns:
            Dict mapping agent names to their AgentStats containing:
            - unique_tool_names: List[str] - Tools used by this agent
            - total_llm_calls: int - Number of LLM calls by this agent
            - total_tool_calls: int - Number of tool calls by this agent
            - llm_calls_failed: int - Number of failed LLM calls
            - tool_calls_failed: int - Number of failed tool calls
            - total_tools_duration: float - Total duration of tool calls (ms)
            - total_llm_duration: float - Total duration of LLM calls (ms)
            - llm_input_tokens: int - Total input tokens
            - llm_output_tokens: int - Total output tokens
            - llm_total_tokens: int - Total tokens (input + output)
            - tool_total_tokens: int - Total tokens used by tools under this agent
        """
        if not self.execution_tree:
            return {}

        agent_stats = {}

        # Find all agent nodes in the execution tree
        for trace_roots in self.execution_tree.traces.values():
            for root in trace_roots:
                self._collect_agent_stats(root, agent_stats)

        return agent_stats

    def _collect_agent_stats(self, node, agent_stats: Dict[str, AgentStats]) -> None:
        """
        Recursively traverse the execution tree to collect statistics for each agent.

        This improved version handles both direct agent spans and agent task spans.

        Args:
            node: Current SpanNode being processed
            agent_stats: Dictionary to accumulate statistics per agent
        """
        # Strategy 1: Direct agent span
        if node.span.entity_type == "agent":
            agent_name = node.span.entity_name
            if agent_name not in agent_stats:
                agent_stats[agent_name] = AgentStats()

            # Collect all descendant spans for this agent
            descendant_spans = self._get_descendant_spans(node)
            self._calculate_agent_stats(agent_stats[agent_name], descendant_spans)

        # Strategy 2: Agent task span (e.g., "documentation_agent.task")
        elif node.span.entity_type == "task":
            # Check if this task belongs to an agent
            agent_name = self._extract_agent_from_task(node.span)
            if agent_name:
                if agent_name not in agent_stats:
                    agent_stats[agent_name] = AgentStats()

                # Collect all descendant spans for this agent task
                descendant_spans = self._get_descendant_spans(node)
                self._calculate_agent_stats(agent_stats[agent_name], descendant_spans)

        # Continue traversing children
        for child in node.children:
            self._collect_agent_stats(child, agent_stats)

    def _extract_agent_from_task(self, span) -> Optional[str]:
        """
        Extract agent name from task span using attributes or name patterns.

        Examples:
        - span with agent_id="documentation_agent" -> "documentation_agent"
        - span with entity_name="documentation_agent.task" -> "documentation_agent"
        - span with entity_name="website_selector_agent" -> "website_selector_agent"
        - span with entity_name="LangGraph" -> None (not an agent task)

        Args:
            span: SpanEntity object

        Returns:
            Agent name if this is an agent task, None otherwise
        """
        # Strategy 1: Use agent_id attribute (most reliable)
        if (
            hasattr(span, "attributes")
            and span.attributes
            and "agent_id" in span.attributes
        ):
            return span.attributes["agent_id"]

        # Strategy 2: Extract from entity path (only if it looks like an agent)
        if (
            hasattr(span, "attributes")
            and span.attributes
            and "traceloop.entity.path" in span.attributes
        ):
            path = span.attributes["traceloop.entity.path"]
            if isinstance(path, str) and "." in path:
                potential_agent = path.split(".")[0]
                # Only use path if it looks like an agent name
                if (
                    "agent" in potential_agent.lower()
                    and potential_agent.lower() != "agent"
                ):
                    return potential_agent

        # Strategy 3: Extract from span name/entity_name (fallback)
        task_name = span.entity_name if hasattr(span, "entity_name") else None
        if not task_name:
            return None

        # Remove .task suffix if present
        base_name = (
            task_name.replace(".task", "") if task_name.endswith(".task") else task_name
        )

        # Skip generic "agent" - it's not specific enough
        if base_name.lower() == "agent":
            return None

        # Check if this looks like an agent name (but not just "agent")
        if (
            "agent" in base_name.lower() and len(base_name) > 5
        ):  # More than just "agent"
            return base_name

        # Check against known agent names from direct agent spans
        known_agents = {span.entity_name for span in self.agent_spans}
        if base_name in known_agents:
            return base_name

        return None

    def _get_descendant_spans(self, node) -> List[SpanEntity]:
        """
        Get all descendant spans from a given node.

        Args:
            node: SpanNode to start traversal from

        Returns:
            List of all descendant SpanEntity objects
        """
        spans = []

        # Add current span
        spans.append(node.span)

        # Recursively collect all children
        for child in node.children:
            spans.extend(self._get_descendant_spans(child))

        return spans

    def _calculate_agent_stats(
        self, stats: AgentStats, spans: List[SpanEntity]
    ) -> None:
        """
        Calculate statistics for an agent from its descendant spans.

        Args:
            stats: AgentStats object to update
            spans: List of spans belonging to this agent
        """
        # Use a set to collect unique tool names, then convert to sorted list at the end
        unique_tools = set(stats.unique_tool_names)

        for span in spans:
            # Tool statistics
            if span.entity_type == "tool":
                stats.total_tool_calls += 1
                if span.contains_error:
                    stats.tool_calls_failed += 1
                if span.entity_name:
                    unique_tools.add(span.entity_name)
                if span.duration is not None:
                    stats.total_tools_duration += span.duration

            # LLM statistics
            elif span.entity_type == "llm":
                stats.total_llm_calls += 1
                if span.contains_error:
                    stats.llm_calls_failed += 1
                if span.duration is not None:
                    stats.total_llm_duration += span.duration

                # Token statistics
                if span.attrs:
                    # Input tokens
                    if span.attrs.get("input_tokens") is not None:
                        try:
                            token_value = int(span.attrs["input_tokens"])
                            if token_value >= 0:
                                stats.llm_input_tokens += token_value
                        except (ValueError, TypeError):
                            pass

                    # Output tokens
                    if span.attrs.get("output_tokens") is not None:
                        try:
                            token_value = int(span.attrs["output_tokens"])
                            if token_value >= 0:
                                stats.llm_output_tokens += token_value
                        except (ValueError, TypeError):
                            pass

                    # Total tokens
                    if span.attrs.get("total_tokens") is not None:
                        try:
                            token_value = int(span.attrs["total_tokens"])
                            if token_value >= 0:
                                stats.llm_total_tokens += token_value
                        except (ValueError, TypeError):
                            pass

        # Update unique tool names as sorted list
        stats.unique_tool_names = sorted(list(unique_tools))
